(window.webpackJsonp=window.webpackJsonp||[]).push([[6],{361:function(t,v,_){"use strict";_.r(v);var e=_(17),l=Object(e.a)({},(function(){var t=this,v=t.$createElement,_=t._self._c||v;return _("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[_("h1",{attrs:{id:"开发者文档"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#开发者文档"}},[t._v("#")]),t._v(" 开发者文档")]),t._v(" "),_("p",[t._v("如果您认真阅读了用户文档，一定会对汉字自动拆分的实现感到惊奇。的确，汉字的形状变化万千，各种编码方案对其的拆分也各不相同，数不胜数，异常复杂。")]),t._v(" "),_("p",[t._v("然而，汉字的可能拆分方式是无穷无尽的吗？我们知道，汉字的笔画数量是有限的，如果我们限制拆分以笔画为最小单位，拆出的字根中每个字根至少包含一个笔画，则汉字的可能拆分方式的数量必然是一个有限大——尽管确实很大——的数。枚举出有限多的拆分方式中，我们再根据确定的规则自动化选取最佳的拆分，就实现了汉字自动拆分。本系统之所以可行，正是基于如此简单的原理。")]),t._v(" "),_("p",[t._v("那么汉字的可能拆分数量大约有多大呢？经过简单的计算，它大约略小于笔画数量的阶乘。一个十笔的字有数十万种拆分，而一个二十笔的字的拆分数量已经超出了任何计算机所能存储的极限。因而如上原理的直接应用又是不可能的。")]),t._v(" "),_("p",[t._v("所幸，基于汉字作为表意文字的特性，绝大多数汉字内在地划分成多个部件（例如形声字、会意字等），部件又可以划分为更小的部件，经过逐级分解之后可以用六七百个基本部件以简单的几何关系组合而成。而对于绝大多数的形码而言，字根数量不过二三百个，所进行的拆分也基本上是针对基本部件的拆分，极少出现一个字根横跨两个基本部件的情况。因此我们引入了本系统最重要的一个假设：")]),t._v(" "),_("blockquote",[_("p",[t._v("分部假设：含有多个部件的汉字的拆分结果，可以近似地由每个部件的拆分结果，以及这些部件相互组合的几何关系决定。")])]),t._v(" "),_("p",[t._v("基本部件的笔画数量少，因而对它们进行枚举是可以做到的。由此我们引出了本系统的顶层架构：")]),t._v(" "),_("ol",[_("li",[t._v("基本部件拆分为字根：由于不同编码方案天差地别，为了最大程度满足它们的需求，我们针对基本部件枚举所有可能的拆分，然后以拆分规则筛选出唯一的拆分；")]),t._v(" "),_("li",[t._v("用基本部件确定其他汉字：将其他汉字表示为由基本部件构成的树状结构；")]),t._v(" "),_("li",[t._v("根据「基本部件的拆分」和「其他汉字的树状结构」进行编码。")])])])}),[],!1,null,null,null);v.default=l.exports}}]);